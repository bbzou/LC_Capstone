{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# from HelperFunctions import minibatch \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from HelperFunctions import minibatch, dummify_columns, undummify, feature_standardize, label_encode_column, columns_of_type\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, AdaBoostRegressor\n",
    "randomForest = RandomForestRegressor()\n",
    "gbm = GradientBoostingRegressor()\n",
    "abr = AdaBoostRegressor()\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "from lightgbm import LGBMRegressor\n",
    "lgb = LGBMRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_prob(unsampled_df,sampled_df,sampled_prob): # sampled_df, sampled_prob can also be test_df, test_prob\n",
    "    # turning the predicted probability into a dataframe with column name default_prob\n",
    "    sample_prob_df=pd.DataFrame(sampled_prob[:,0],columns=['sampled_prob'])\n",
    "    # find actual default rate for each class\n",
    "    grade_rate=unsampled_df.groupby('grade')['loan_status'].apply(lambda x:(x=='Default').sum()/x.count())\n",
    "    grade_rate_dict=grade_rate.to_dict()\n",
    "    # mapping the unsampled_df default rates to the test_df=sampled_df\n",
    "    # and then getting the array of default_rates in the test_df\n",
    "    sampled_df['default_rate']=sampled_df['grade'].map(grade_rate_dict)\n",
    "    sampled_df.reset_index(drop=True, inplace=True)\n",
    "    sample_prob_df.reset_index(drop=True, inplace=True)\n",
    "    pre_adjust_df=pd.concat([sampled_df,sample_prob_df],axis=1)\n",
    "    # Adjusting the default_probability to the true probability (accounting for down/up sampling)    \n",
    "    sampled_frac=0.5\n",
    "    real_prob=[]\n",
    "    for row in pre_adjust_df.loc[:,['default_rate','sampled_prob']].iterrows():\n",
    "        beta=sampled_frac/(1-row[1]['default_rate'])\n",
    "        real_prob.append(beta*row[1]['sampled_prob']/((beta-1)*row[1]['sampled_prob']+1))\n",
    "        #     prob=1/(1+(1/original_fraction-1)/(1/sampled_fraction-1)*(1/sampled_prob-1))\n",
    "    a=pd.DataFrame(real_prob,columns=['actual_prob'])\n",
    "    b=pd.DataFrame(sampled_prob[:,0],columns=['downsampled_prob'])\n",
    "    return pd.concat([a,b],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('down_sampled_df_v2.csv',index_col='id')\n",
    "pre_df=pd.read_csv('pre_downsample_df.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_weight_dict={'A':1,\n",
    "                  'B':2,\n",
    "                  'C':3,\n",
    "                  'D':4,\n",
    "                  'E':5,\n",
    "                  'G':6}\n",
    "df['weight']=df['grade'].map(grade_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list=['sub_grade','issue_d','zip_code','RANDOM']\n",
    "df.drop(drop_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>mort_frac</th>\n",
       "      <th>card_frac</th>\n",
       "      <th>active_card_frac</th>\n",
       "      <th>active_revol_frac</th>\n",
       "      <th>active_install_frac</th>\n",
       "      <th>open_revol_frac</th>\n",
       "      <th>good_acc_frac</th>\n",
       "      <th>loan_duration</th>\n",
       "      <th>return_rate</th>\n",
       "      <th>RANDOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65251140</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.89</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.040767</td>\n",
       "      <td>0.220221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62519711</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.89</td>\n",
       "      <td>A</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>RENT</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>37.566667</td>\n",
       "      <td>0.033656</td>\n",
       "      <td>0.008344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50646937</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.32</td>\n",
       "      <td>A</td>\n",
       "      <td>A1</td>\n",
       "      <td>5</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0.027468</td>\n",
       "      <td>0.412407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16442318</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>36</td>\n",
       "      <td>7.69</td>\n",
       "      <td>A</td>\n",
       "      <td>A4</td>\n",
       "      <td>7</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>36.533333</td>\n",
       "      <td>0.037775</td>\n",
       "      <td>0.562369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49924755</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>5.32</td>\n",
       "      <td>A</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>36.533333</td>\n",
       "      <td>0.025984</td>\n",
       "      <td>0.941376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  funded_amnt  term  int_rate grade sub_grade  emp_length  \\\n",
       "0  65251140      25000.0    36      7.89     A        A5           1   \n",
       "1  62519711      14000.0    36      6.89     A        A3           3   \n",
       "2  50646937       5000.0    36      5.32     A        A1           5   \n",
       "3  16442318       6500.0    36      7.69     A        A4           7   \n",
       "4  49924755      16000.0    36      5.32     A        A1           1   \n",
       "\n",
       "  home_ownership  annual_inc verification_status  ... mort_frac card_frac  \\\n",
       "0       MORTGAGE     94000.0     Source Verified  ...  0.100000  0.578947   \n",
       "1           RENT     45000.0        Not Verified  ...  0.222222  0.857143   \n",
       "2       MORTGAGE     80000.0        Not Verified  ...  0.031250  0.650000   \n",
       "3       MORTGAGE     61000.0        Not Verified  ...  0.133333  0.500000   \n",
       "4       MORTGAGE     98000.0     Source Verified  ...  0.119048  0.533333   \n",
       "\n",
       "  active_card_frac active_revol_frac active_install_frac  open_revol_frac  \\\n",
       "0         0.363636          0.368421              -999.0         0.578947   \n",
       "1         0.500000          0.428571              -999.0         0.428571   \n",
       "2         0.538462          0.450000              -999.0         0.750000   \n",
       "3         0.666667          0.500000              -999.0         0.666667   \n",
       "4         0.187500          0.166667              -999.0         0.433333   \n",
       "\n",
       "   good_acc_frac  loan_duration  return_rate    RANDOM  \n",
       "0       0.500000      34.500000     0.040767  0.220221  \n",
       "1       0.333333      37.566667     0.033656  0.008344  \n",
       "2       0.656250      34.500000     0.027468  0.412407  \n",
       "3       0.600000      36.533333     0.037775  0.562369  \n",
       "4       0.333333      36.533333     0.025984  0.941376  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=df.drop(['loan_status','return_rate'],axis=1)\n",
    "y_train=df.loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list=columns_of_type(x_train,'string')\n",
    "cont_list=columns_of_type(x_train,'number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encode ALL Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoded_df=label_encode_column(x_train,cat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize ALL Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df=label_encoded_df.apply(lambda x:feature_standardize(x,scaleType='standardize'),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUSTOM SCORING FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metric import accuracy_score\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "def grade_weighted_accuracy(y_true,y_pred,sample_weight):\n",
    "    weighted_acc=accuracy_score(y_true,y_pred,normalize=True,sample_weight)\n",
    "    return weighted_acc    \n",
    "grade_weighted_scorer = make_scorer(grade_weighted_accuracy, needs_proba=False, sample_weight=df['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_para_forest = {\n",
    "    'n_estimators': range(20, 80, 7),\n",
    "    'max_depth':[2,3],\n",
    "    'max_features':[1, 2],\n",
    "    'min_samples_leaf':[1,2],\n",
    "    'min_samples_split':[2,3]\n",
    "}\n",
    "grid_search_forest = GridSearchCV(ensemble.RandomForestClassifier(class_weight='balanced'),\\\n",
    "                                  grid_para_forest, cv=3,  n_jobs=-1,\\\n",
    "                                  scoring=grade_weighted_scorer,return_train_score=False)\n",
    "grid_search_forest.fit(x_train,y_train)\n",
    "grid_search_forest.predict(x_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid_search_forest.predict(final_train_df)\n",
    "y_true=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters:', grid_search_forest.best_params_)\n",
    "print('best score:', grid_search_forest.best_score_)\n",
    "confusion_matrix(y, grid_search_forest.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K mean clustering performed on categorical variables\n",
    "# perform for train (non-test) set\n",
    "nominal_var_cluster_num=[]\n",
    "nominal_var_cluster_num_test=[]\n",
    "for cat_var in nominal_var_processed:\n",
    "    # dummifying the nominal categorical variable\n",
    "    dummified_column=pd.get_dummies(x.loc[:,cat_var],prefix=cat_var, prefix_sep='__')\n",
    "    df_for_cluster=pd.concat([y,dummified_column],axis=1,sort='False')\n",
    "    print(cat_var)\n",
    "    # Finding the optimal number of clusters and storing into nominal_var_cluster_num\n",
    "    kmax = df_for_cluster.shape[1]\n",
    "    KNumberChoice=range(2, kmax)\n",
    "    # dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2\n",
    "    # Doing mulitple trials for each category\n",
    "    cluster_count=[]\n",
    "    for trial_num in range(0,5):\n",
    "        sil = []\n",
    "        for k in range(2, kmax):\n",
    "            kmeans = KMeans(n_clusters = k,random_state=trial_num,init='k-means++').fit(df_for_cluster)\n",
    "            labels = kmeans.labels_\n",
    "            sil.append(silhouette_score(df_for_cluster, labels, metric = 'euclidean'))\n",
    "        if np.argmax(sil)<0.2: # defining threshold for 1 cluster\n",
    "            cluster_count.append(1)\n",
    "        else:\n",
    "            cluster_count.append(KNumberChoice[np.argmax(sil)])\n",
    "    nominal_var_cluster_num.append(max(set(cluster_count), key=cluster_count.count))\n",
    "print(nominal_var_cluster_num)\n",
    "print(nominal_var_cluster_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the known cluster number for each categorical variable, perform the clustering\n",
    "# perform for train (non-test) set\n",
    "for ind,cat_var in enumerate(nominal_var_processed):\n",
    "    dummified_column=pd.get_dummies(x.loc[:,cat_var],prefix=cat_var, prefix_sep='__')\n",
    "    df_for_cluster=pd.concat([y,dummified_column],axis=1,sort='False')\n",
    "    kmeans=KMeans(n_clusters=nominal_var_cluster_num[ind]).fit(df_for_cluster)\n",
    "    x.loc[:,cat_var]=kmeans.labels_\n",
    "    \n",
    "clustered_df=pd.concat([y,x],axis=1,sort='False')    \n",
    "clustered_df_test=pd.concat([y_test,x_test],axis=1,sort='False')    \n",
    "print(clustered_df.shape)\n",
    "print(clustered_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns with pure 0's\n",
    "undummified_clustered_df=clustered_df.loc[:,(clustered_df != 0).any(axis=0)]\n",
    "undummified_clustered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### ONLY FOR NON-TEST !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "####################### ONLY FOR NON-TEST !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Removing sub-categories with low counts and their associated observations (if less than 2% of total observation)\n",
    "boolmatrix=[]\n",
    "non_cont_columns=dummified_clustered_df.columns[~dummified_clustered_df.columns.isin(cont_var_for_tuning)]\n",
    "for cat_feature in non_cont_columns:\n",
    "    if dummified_clustered_df.loc[:,cat_feature].sum()<0.020*dummified_clustered_df.shape[0]:\n",
    "        print('yes')\n",
    "        boolvec=(dummified_clustered_df.loc[:,cat_feature]==1)\n",
    "        boolmatrix.append(list(boolvec))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### ONLY FOR NON-TEST !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "####################### ONLY FOR NON-TEST !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# creating boolean vector to takeout observations that have categorical low count observations\n",
    "if boolmatrix!=[]:\n",
    "    reduction_bool_vec=np.any(np.array(boolmatrix).transpose(),axis=1)\n",
    "    temp_df=dummified_clustered_df[~reduction_bool_vec]\n",
    "    purged_dummified_clustered_df=temp_df.loc[:,(temp_df != 0).any(axis=0)]\n",
    "else:\n",
    "    purged_dummified_clustered_df=dummified_clustered_df\n",
    "print(purged_dummified_clustered_df.shape)\n",
    "print(dummified_clustered_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing from the test set columns there were removed from the training set!\n",
    "cols_to_keep=set(dummified_clustered_df_test.columns)&(set(purged_dummified_clustered_df.columns))\n",
    "\n",
    "\n",
    "purged_dummified_clustered_df_test=dummified_clustered_df_test.loc[:,list(cols_to_keep)]\n",
    "purged_dummified_clustered_df=dummified_clustered_df.loc[:,list(cols_to_keep)+['SalePrice']]\n",
    "\n",
    "# purged_dummified_clustered_df.reset_index(inplace=True)\n",
    "# purged_dummified_clustered_df.set_index('Id')\n",
    "# purged_dummified_clustered_df_test.reset_index(inplace=True)\n",
    "# purged_dummified_clustered_df_test.set_index('Id')\n",
    "# purged_dummified_clustered_df\n",
    "\n",
    "# purged_dummified_clustered_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undummify(dataframe):\n",
    "    tot_col=dataframe.columns\n",
    "    cat_col=list(tot_col[tot_col.str.contains('__')])\n",
    "    cat_col_split=set(map(lambda x:x.split('__')[0],cat_col))\n",
    "    cat_dict={}\n",
    "    for col in cat_col_split:\n",
    "        sub_df=dataframe[cat_col].loc[:,list(map(lambda x:col in x, dataframe[cat_col].columns))]\n",
    "        for i in sub_df.columns:\n",
    "            label_num=int(i.split('__')[1])\n",
    "            sub_df.loc[:,i]=np.array(sub_df.loc[:,i])*label_num\n",
    "        cat_dict[col]=sub_df.sum(axis=1)+1\n",
    "    df1=dataframe.drop(cat_col,axis=1)\n",
    "    df2=pd.DataFrame(cat_dict)\n",
    "    return pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of HelperFunctions failed: Traceback (most recent call last):\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/home/auscheng/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 302, in update_instances\n",
      "    visited.update({id(obj):obj})\n",
      "MemoryError\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 17, cost: 803.0\n",
      "Run 1, iteration: 2/100, moves: 10, cost: 799.0\n",
      "Run 1, iteration: 3/100, moves: 4, cost: 799.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 19, cost: 794.0\n",
      "Run 2, iteration: 2/100, moves: 3, cost: 794.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 21, cost: 806.0\n",
      "Run 3, iteration: 2/100, moves: 7, cost: 806.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 21, cost: 801.0\n",
      "Run 4, iteration: 2/100, moves: 5, cost: 798.0\n",
      "Run 4, iteration: 3/100, moves: 1, cost: 797.0\n",
      "Run 4, iteration: 4/100, moves: 0, cost: 797.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 20, cost: 796.0\n",
      "Run 5, iteration: 2/100, moves: 7, cost: 794.0\n",
      "Run 5, iteration: 3/100, moves: 0, cost: 794.0\n",
      "Best run was number 2\n",
      "[[12  5 15  6  6  5  1  3  3 12]\n",
      " [ 2  7 14 12 14 10  7  0 11 14]\n",
      " [19 14  3  0 12  8  8 12  2  2]\n",
      " [10  9  4  1 11  1 12 13 14  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "# random categorical data\n",
    "data = np.random.choice(20, (100, 10))\n",
    "\n",
    "km = KModes(n_clusters=4, init='Huang', n_init=5, verbose=1)\n",
    "\n",
    "clusters = km.fit_predict(data)\n",
    "\n",
    "# Print the cluster centroids\n",
    "print(km.cluster_centroids_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  2,  5, 19,  1, 19,  7,  6,  0,  7],\n",
       "       [ 0,  1,  0, 16, 19,  4, 10,  9,  5,  4],\n",
       "       [14,  5, 19,  7,  5,  1,  1,  9,  4,  2],\n",
       "       [14, 13, 14, 16, 14, 15,  2,  4, 15,  0],\n",
       "       [ 6,  0, 19,  0,  8, 15, 12,  3,  3,  2],\n",
       "       [ 1,  7, 18,  1, 17,  7,  8,  0, 11,  8],\n",
       "       [15,  6, 15, 15,  2,  4,  1,  2,  3,  5],\n",
       "       [ 6,  7,  4,  2,  5,  5,  7, 14,  5,  1],\n",
       "       [13, 14,  2, 10, 17, 17, 18,  7,  9,  7],\n",
       "       [ 7,  1, 14,  9, 14,  4, 18,  7,  0, 13],\n",
       "       [16,  8,  3,  7, 14,  1,  8, 19,  2, 17],\n",
       "       [13, 14,  2,  2, 10,  8, 10, 18,  6,  5],\n",
       "       [ 3,  6, 17,  8, 12, 11,  3, 12,  4,  0],\n",
       "       [13,  3, 11,  0, 12,  2,  8, 12, 18, 19],\n",
       "       [ 4, 12,  3,  2,  4, 18,  8,  6,  6,  2],\n",
       "       [14,  5, 16, 18,  0, 11, 14,  6, 17, 19],\n",
       "       [ 7, 12, 13, 16, 19, 14, 11, 13, 17,  3],\n",
       "       [ 2,  3,  8, 13,  9,  2,  7,  8, 19, 17],\n",
       "       [19,  3, 17,  8, 17,  5,  6,  5,  7,  4],\n",
       "       [17, 18, 17,  9,  6, 19, 11, 14, 16, 12],\n",
       "       [ 3,  5, 15, 13, 13,  7, 14, 14,  6, 11],\n",
       "       [ 1, 14, 14,  7,  5,  4,  2, 10, 11, 15],\n",
       "       [ 3, 14,  9,  3,  5,  8,  8,  6, 11,  0],\n",
       "       [11,  7,  5,  0,  3,  8,  9, 11, 11, 19],\n",
       "       [10, 15,  5, 12, 10, 12, 15, 10, 12,  7],\n",
       "       [ 8,  7, 14,  7, 11, 16, 18, 14,  7,  5],\n",
       "       [ 9, 10, 14, 10,  1, 10,  1, 17,  6,  3],\n",
       "       [16, 10, 15, 18,  6, 19,  1,  1,  0,  6],\n",
       "       [19,  4,  3,  6, 17, 19,  6,  2, 15, 16],\n",
       "       [19, 12,  8,  5, 11,  6, 17, 14,  2, 17],\n",
       "       [ 2,  4,  1, 11,  7,  5, 16, 14,  4, 15],\n",
       "       [ 4,  2,  7,  0, 12,  5, 11, 12,  4, 16],\n",
       "       [ 2,  0,  8,  5,  9,  7,  7,  1,  9, 14],\n",
       "       [12,  5,  4, 17, 12,  2, 13, 12, 19,  9],\n",
       "       [17,  8,  7, 12, 19, 13, 12,  3,  6, 10],\n",
       "       [10, 11, 15, 13, 18, 17, 19, 10,  7,  2],\n",
       "       [19, 15, 10, 10, 16, 10,  9,  3,  9,  6],\n",
       "       [ 8, 11, 11, 12, 14, 13,  6, 15, 14, 12],\n",
       "       [12, 15, 17,  7,  0, 16,  0, 19,  3, 16],\n",
       "       [ 7,  5,  6, 10, 14,  2,  9,  1,  6, 12],\n",
       "       [ 2,  8, 18, 16, 14, 15,  7,  0, 11,  0],\n",
       "       [13,  2,  6,  7,  1, 18,  8, 14,  2,  8],\n",
       "       [10,  5,  7, 14,  3,  6, 13, 14,  2, 13],\n",
       "       [ 8,  4,  1,  7, 17, 11, 11, 12, 16, 11],\n",
       "       [19, 13, 10, 10,  8, 16,  8,  7,  7,  2],\n",
       "       [ 8, 19, 14, 10,  8,  5,  9, 14,  9, 17],\n",
       "       [12,  7, 17,  1,  1, 10,  6, 11,  7,  3],\n",
       "       [ 8,  0,  7, 18,  4,  7,  5, 12,  5, 15],\n",
       "       [ 5,  5, 17, 14,  6, 19,  2, 19,  1, 15],\n",
       "       [16,  4,  3,  6, 12, 17, 18,  5, 10, 12],\n",
       "       [18, 10, 15, 14,  2,  8, 16, 17,  1,  9],\n",
       "       [13, 11, 12,  5,  5,  6, 10,  2,  0, 10],\n",
       "       [19, 18, 15, 12,  8, 12, 15, 18, 14,  2],\n",
       "       [ 3,  8, 13,  7,  3, 12,  1,  6, 13, 13],\n",
       "       [19,  0, 15, 11,  6,  4,  1, 16,  9,  2],\n",
       "       [11,  9,  0, 15,  2, 16, 17,  2,  4, 14],\n",
       "       [15, 14,  3, 18,  9, 10,  3,  0, 11, 13],\n",
       "       [ 3, 17, 14,  3,  4, 12, 16,  0,  8, 11],\n",
       "       [ 2,  7,  1,  3,  6,  5, 11,  3,  3, 14],\n",
       "       [12,  9, 18, 11, 11,  1,  5, 11, 14, 12],\n",
       "       [10, 14,  9, 17, 11,  3, 12, 11,  1,  9],\n",
       "       [17, 13, 12,  1,  7,  2,  9, 13, 14,  0],\n",
       "       [12,  6,  6,  0, 16,  2,  4,  3, 16,  2],\n",
       "       [ 2,  8,  8, 12, 12, 13, 19,  1,  1,  0],\n",
       "       [10, 13, 12,  4, 19,  7,  4,  8, 16, 12],\n",
       "       [ 4, 19,  6,  9,  0,  8,  9, 13,  8,  2],\n",
       "       [14,  9, 16,  1, 12, 19, 19, 14, 14,  0],\n",
       "       [ 7, 16, 12,  1, 16, 18,  4, 13,  3,  8],\n",
       "       [ 8,  6, 11, 17,  8,  6,  5,  5, 16,  3],\n",
       "       [19,  4,  2, 12,  3,  1,  1, 12, 19,  0],\n",
       "       [16, 19, 18, 14, 12,  8, 15,  5,  6,  7],\n",
       "       [10, 14,  2,  9, 10, 18,  1, 19,  2, 15],\n",
       "       [10,  8, 10,  6, 18, 16, 18, 13,  0,  7],\n",
       "       [ 1, 15, 13, 16, 14,  2,  7, 11, 18,  7],\n",
       "       [14,  7, 16, 15,  2, 14, 18,  3,  4,  8],\n",
       "       [ 7,  6, 12, 17, 14, 11, 15, 11,  3, 11],\n",
       "       [10, 14,  4, 11,  2,  9, 12, 13, 17, 11],\n",
       "       [ 1, 19,  8, 12,  6,  7,  0,  2,  3, 19],\n",
       "       [ 0, 18,  9,  2, 11, 19,  5, 18, 16,  8],\n",
       "       [ 7,  9,  9, 18,  6,  6,  3, 15,  9,  3],\n",
       "       [12, 15,  2, 15,  3, 19, 13, 16,  8, 17],\n",
       "       [19, 15,  1,  0,  1,  5,  8, 11, 16,  2],\n",
       "       [11, 17, 12, 18,  3, 10,  0, 13,  2,  5],\n",
       "       [ 0,  0, 15, 17,  2,  9,  6,  5, 15, 15],\n",
       "       [18,  2, 12,  2,  1, 10,  7,  3, 13,  5],\n",
       "       [19, 16, 16, 19,  5,  8, 10, 15,  6,  9],\n",
       "       [13,  1,  9, 10, 19,  5, 17,  2,  3,  0],\n",
       "       [12,  9,  4,  7,  2,  4, 12,  2,  3, 13],\n",
       "       [16,  8,  2,  6,  8,  3, 13,  3, 19, 15],\n",
       "       [ 0, 11,  8,  6,  2,  9, 19,  3,  5,  8],\n",
       "       [11, 11,  3, 14, 15,  6, 15,  6, 12, 16],\n",
       "       [11,  9, 14, 12, 14, 15,  7,  8, 10, 14],\n",
       "       [17, 13,  3, 18, 19,  2, 13, 12,  9,  8],\n",
       "       [ 6, 12,  8,  6, 18,  8,  4,  9,  7, 13],\n",
       "       [ 4,  1, 18,  9,  5,  1, 12, 16,  1, 17],\n",
       "       [10, 11,  3,  5,  1,  1,  3, 13,  8,  9],\n",
       "       [ 2,  7, 16,  3, 13, 14,  8,  2, 11,  8],\n",
       "       [12,  5, 13,  3,  6,  3,  3,  9, 19, 12],\n",
       "       [ 2, 11,  6,  6,  4, 10,  7,  0,  8, 14],\n",
       "       [ 5, 19, 19, 12,  3,  5, 19,  9,  8, 15]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
