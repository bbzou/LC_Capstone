{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LC_Classifier(df,col_to_drop,target,**grade_weight_dict):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from HelperFunctions import feature_standardize, label_encode_column, columns_of_type\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics.scorer import make_scorer\n",
    "    '''\n",
    "    df: dataframe of interest (for x_train)\n",
    "    col_to_drop: accepts a list of column names (strings) that will be dropped from the model\n",
    "    target: the target variable, in the format of a string\n",
    "    **grade_weight_dict: the dictionary for weights for different grades\n",
    "    **grade_weight_dict is in the form of:\n",
    "    grade_dict={'A':1,\n",
    "                'B':1,\n",
    "                'C':1,\n",
    "                'D':1,\n",
    "                'E':1,\n",
    "                'F':1,\n",
    "                'G':1}\n",
    "    '''\n",
    "    df['weight']=df['grade'].map(grade_weight_dict)\n",
    "    grade_weight_array=df['weight'].values\n",
    "    index = df.index\n",
    "    grade_weight_frame = pd.DataFrame(grade_weight_array, index=index)\n",
    "\n",
    "    df.drop(col_to_drop,axis=1,inplace=True)\n",
    "    x_train=df.drop([target],axis=1)\n",
    "    y_train=df.loc[:,target]\n",
    "    \n",
    "    cat_list=columns_of_type(x_train,'string')\n",
    "    cont_list=columns_of_type(x_train,'number')\n",
    "    \n",
    "    label_encoded_df=label_encode_column(x_train,cat_list)\n",
    "    \n",
    "    final_train_df=label_encoded_df.apply(lambda x:feature_standardize(x,scaleType='standardize'),axis=0)\n",
    "    \n",
    "    def grade_weighted_accuracy(y_true,y_pred,sample_weight):\n",
    "\n",
    "        weighted_acc=accuracy_score(y_true,y_pred,\n",
    "                                    sample_weight=sample_weight.loc[y_true.index.values].values.reshape(-1),\n",
    "                                    normalize=True)\n",
    "        return weighted_acc    \n",
    "\n",
    "    score_params = {\"sample_weight\": grade_weight_frame}\n",
    "\n",
    "    grade_weighted_scorer = make_scorer(score_func=grade_weighted_accuracy,\n",
    "                                        greater_is_better=True,\n",
    "                                        needs_proba=False,\n",
    "                                        needs_threshold=False,\n",
    "                                        **score_params)\n",
    "    grid_para_forest = {\n",
    "    'n_estimators': [500],\n",
    "    'max_depth':[15],\n",
    "    'max_features':[10],\n",
    "    'min_samples_leaf':[3],\n",
    "    'min_samples_split':[3]\n",
    "    }\n",
    "\n",
    "    grid_search_forest = GridSearchCV(estimator=RandomForestClassifier(),\\\n",
    "                                      param_grid=grid_para_forest,\\\n",
    "                                      n_jobs=-1,\\\n",
    "                                      scoring=grade_weighted_scorer,cv=5,\\\n",
    "                                      return_train_score=False)\n",
    "    grid_search_forest.fit(final_train_df,y_train)\n",
    "    sampled_prob=grid_search_forest.predict_proba(final_train_df)\n",
    "    return sampled_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv('down_sampled_df_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df=pd.read_csv('pre_downsample_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list=['sub_grade','issue_d','zip_code','RANDOM','id','weight','loan_duration','return_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_weight_dict={'A':1,\n",
    "            'B':1,\n",
    "            'C':1,\n",
    "            'D':1,\n",
    "            'E':1,\n",
    "            'F':1,\n",
    "            'G':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auscheng/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "sampled_prob=LC_Classifier(df,drop_list,'loan_status',grade_weight_dict=grade_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_prob(unsampled_df,sampled_df,sampled_prob): # sampled_df, sampled_prob can also be test_df, test_prob\n",
    "    # turning the predicted probability into a dataframe with column name default_prob\n",
    "    sample_prob_df=pd.DataFrame(sampled_prob[:,0],columns=['sampled_prob'])\n",
    "    # find actual default rate for each class\n",
    "    grade_rate=unsampled_df.groupby('grade')['loan_status'].apply(lambda x:(x=='Default').sum()/x.count())\n",
    "    grade_rate_dict=grade_rate.to_dict()\n",
    "    # mapping the unsampled_df default rates to the test_df=sampled_df\n",
    "    # and then getting the array of default_rates in the test_df\n",
    "    sampled_df['default_rate']=sampled_df['grade'].map(grade_rate_dict)\n",
    "    sampled_df.reset_index(drop=True, inplace=True)\n",
    "    sample_prob_df.reset_index(drop=True, inplace=True)\n",
    "    pre_adjust_df=pd.concat([sampled_df,sample_prob_df],axis=1)\n",
    "    # Adjusting the default_probability to the true probability (accounting for down/up sampling)    \n",
    "    sampled_frac=0.5\n",
    "    real_prob=[]\n",
    "    for row in pre_adjust_df.loc[:,['default_rate','sampled_prob']].iterrows():\n",
    "        beta=sampled_frac/(1-row[1]['default_rate'])\n",
    "        real_prob.append(beta*row[1]['sampled_prob']/((beta-1)*row[1]['sampled_prob']+1))\n",
    "        #     prob=1/(1+(1/original_fraction-1)/(1/sampled_fraction-1)*(1/sampled_prob-1))\n",
    "    a=pd.DataFrame(real_prob,columns=['actual_prob'])\n",
    "    b=pd.DataFrame(sampled_prob[:,0],columns=['downsampled_prob'])\n",
    "    return pd.concat([a,b],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting Probabilities to account for downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob_df=adjust_prob(pre_df,df,sampled_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_prob</th>\n",
       "      <th>downsampled_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.238310</td>\n",
       "      <td>0.370411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166306</td>\n",
       "      <td>0.272788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186997</td>\n",
       "      <td>0.301929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.192358</td>\n",
       "      <td>0.309332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.166010</td>\n",
       "      <td>0.272365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.232834</td>\n",
       "      <td>0.363347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.209272</td>\n",
       "      <td>0.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.229440</td>\n",
       "      <td>0.358942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.244386</td>\n",
       "      <td>0.378183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.192216</td>\n",
       "      <td>0.309136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.303614</td>\n",
       "      <td>0.450505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.221897</td>\n",
       "      <td>0.349070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.172995</td>\n",
       "      <td>0.282310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.238379</td>\n",
       "      <td>0.370500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.254108</td>\n",
       "      <td>0.390477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.356167</td>\n",
       "      <td>0.509867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.239242</td>\n",
       "      <td>0.371608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.383813</td>\n",
       "      <td>0.539448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.220149</td>\n",
       "      <td>0.346767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.178509</td>\n",
       "      <td>0.290086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.228880</td>\n",
       "      <td>0.358213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.236351</td>\n",
       "      <td>0.367891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.201409</td>\n",
       "      <td>0.321694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.173013</td>\n",
       "      <td>0.282335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.231201</td>\n",
       "      <td>0.361231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.167213</td>\n",
       "      <td>0.274084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.249830</td>\n",
       "      <td>0.385089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.294721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.186751</td>\n",
       "      <td>0.301588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.205167</td>\n",
       "      <td>0.326778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51842</th>\n",
       "      <td>0.557666</td>\n",
       "      <td>0.561369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51843</th>\n",
       "      <td>0.722153</td>\n",
       "      <td>0.725158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51844</th>\n",
       "      <td>0.654123</td>\n",
       "      <td>0.657515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51845</th>\n",
       "      <td>0.750059</td>\n",
       "      <td>0.752865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51846</th>\n",
       "      <td>0.731665</td>\n",
       "      <td>0.734605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51847</th>\n",
       "      <td>0.746664</td>\n",
       "      <td>0.749496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51848</th>\n",
       "      <td>0.599199</td>\n",
       "      <td>0.602801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51849</th>\n",
       "      <td>0.711487</td>\n",
       "      <td>0.714562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51850</th>\n",
       "      <td>0.652457</td>\n",
       "      <td>0.655856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51851</th>\n",
       "      <td>0.727062</td>\n",
       "      <td>0.730033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51852</th>\n",
       "      <td>0.637047</td>\n",
       "      <td>0.640514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51853</th>\n",
       "      <td>0.593261</td>\n",
       "      <td>0.596882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51854</th>\n",
       "      <td>0.675026</td>\n",
       "      <td>0.678313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51855</th>\n",
       "      <td>0.697636</td>\n",
       "      <td>0.700795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51856</th>\n",
       "      <td>0.613588</td>\n",
       "      <td>0.617144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51857</th>\n",
       "      <td>0.647181</td>\n",
       "      <td>0.650604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51858</th>\n",
       "      <td>0.629888</td>\n",
       "      <td>0.633384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51859</th>\n",
       "      <td>0.610226</td>\n",
       "      <td>0.613793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51860</th>\n",
       "      <td>0.540870</td>\n",
       "      <td>0.544599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51861</th>\n",
       "      <td>0.594208</td>\n",
       "      <td>0.597825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51862</th>\n",
       "      <td>0.549338</td>\n",
       "      <td>0.553055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>0.635043</td>\n",
       "      <td>0.638518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>0.563935</td>\n",
       "      <td>0.567626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>0.708449</td>\n",
       "      <td>0.711543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>0.694671</td>\n",
       "      <td>0.697849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>0.658289</td>\n",
       "      <td>0.661661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51868</th>\n",
       "      <td>0.686360</td>\n",
       "      <td>0.689585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51869</th>\n",
       "      <td>0.698172</td>\n",
       "      <td>0.701329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51870</th>\n",
       "      <td>0.751714</td>\n",
       "      <td>0.754508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51871</th>\n",
       "      <td>0.617805</td>\n",
       "      <td>0.621346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51872 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual_prob  downsampled_prob\n",
       "0         0.238310          0.370411\n",
       "1         0.166306          0.272788\n",
       "2         0.186997          0.301929\n",
       "3         0.192358          0.309332\n",
       "4         0.166010          0.272365\n",
       "5         0.232834          0.363347\n",
       "6         0.209272          0.332300\n",
       "7         0.229440          0.358942\n",
       "8         0.244386          0.378183\n",
       "9         0.192216          0.309136\n",
       "10        0.303614          0.450505\n",
       "11        0.221897          0.349070\n",
       "12        0.172995          0.282310\n",
       "13        0.238379          0.370500\n",
       "14        0.254108          0.390477\n",
       "15        0.356167          0.509867\n",
       "16        0.239242          0.371608\n",
       "17        0.383813          0.539448\n",
       "18        0.220149          0.346767\n",
       "19        0.178509          0.290086\n",
       "20        0.228880          0.358213\n",
       "21        0.236351          0.367891\n",
       "22        0.201409          0.321694\n",
       "23        0.173013          0.282335\n",
       "24        0.231201          0.361231\n",
       "25        0.167213          0.274084\n",
       "26        0.249830          0.385089\n",
       "27        0.181818          0.294721\n",
       "28        0.186751          0.301588\n",
       "29        0.205167          0.326778\n",
       "...            ...               ...\n",
       "51842     0.557666          0.561369\n",
       "51843     0.722153          0.725158\n",
       "51844     0.654123          0.657515\n",
       "51845     0.750059          0.752865\n",
       "51846     0.731665          0.734605\n",
       "51847     0.746664          0.749496\n",
       "51848     0.599199          0.602801\n",
       "51849     0.711487          0.714562\n",
       "51850     0.652457          0.655856\n",
       "51851     0.727062          0.730033\n",
       "51852     0.637047          0.640514\n",
       "51853     0.593261          0.596882\n",
       "51854     0.675026          0.678313\n",
       "51855     0.697636          0.700795\n",
       "51856     0.613588          0.617144\n",
       "51857     0.647181          0.650604\n",
       "51858     0.629888          0.633384\n",
       "51859     0.610226          0.613793\n",
       "51860     0.540870          0.544599\n",
       "51861     0.594208          0.597825\n",
       "51862     0.549338          0.553055\n",
       "51863     0.635043          0.638518\n",
       "51864     0.563935          0.567626\n",
       "51865     0.708449          0.711543\n",
       "51866     0.694671          0.697849\n",
       "51867     0.658289          0.661661\n",
       "51868     0.686360          0.689585\n",
       "51869     0.698172          0.701329\n",
       "51870     0.751714          0.754508\n",
       "51871     0.617805          0.621346\n",
       "\n",
       "[51872 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
